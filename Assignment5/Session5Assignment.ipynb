{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA P2S3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ahBVnrNc3E0U",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rgOGxPDP3Wpp",
        "outputId": "ba32f3e1-46e6-43d3-977a-7b18b0e2c10c",
        "colab": {}
      },
      "source": [
        "!wget -O text.txt https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing\n",
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-02 00:20:32--  https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.167.174, 2404:6800:4007:808::200e\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.167.174|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘text.txt’\n",
            "\n",
            "text.txt                [  <=>               ]  67.68K   236KB/s    in 0.3s    \n",
            "\n",
            "2020-02-02 00:20:33 (236 KB/s) - ‘text.txt’ saved [69307]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E5TKeiOp4jtl",
        "outputId": "38456828-546f-44c0-aa03-168724bcc640",
        "colab": {}
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 69307 characters, 95 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dfj21ORa49Ps",
        "colab": {}
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-01 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "seGHei_D5FGk",
        "colab": {}
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "    return y*(1-y)\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "    y = 2*x\n",
        "    return sigmoid(y) - sigmoid(-y)\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "    return 1 - y*y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wn2v5ZN3ipY",
        "colab_type": "code",
        "outputId": "2cab62d0-540c-44be-8c21-06486b1bbbc9",
        "colab": {}
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTL9J4Rm3ipb",
        "colab_type": "code",
        "outputId": "2088a006-1d30-4630-f0f0-63dcfa81dce9",
        "colab": {}
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHgdthZj3ipe",
        "colab_type": "code",
        "outputId": "e0a8b281-da14-4d5f-9d93-0b398db925f7",
        "colab": {}
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2449186624037092"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2dd-FQn3ipj",
        "colab_type": "code",
        "outputId": "f7a9e955-b1cd-495a-9bc7-7c741cfb2673",
        "colab": {}
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.940014848806378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ICbWNemE6LGV",
        "colab": {}
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "        self.name = name\n",
        "        self.v = value # parameter value\n",
        "        self.d = np.zeros_like(value) # derivative\n",
        "        self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SFuHhqVq6Wge",
        "colab": {}
      },
      "source": [
        "size_a = Hidden_Layer_size # write your code here\n",
        "size_b = z_size# write your code here\n",
        "size_c = X_size# write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-bUkseNnDott",
        "colab": {}
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.add(np.dot(p.W_f.v, z), p.b_f.v))# write your code here\n",
        "    i = sigmoid(np.add(np.dot(p.W_i.v, z), p.b_i.v))# write your code here\n",
        "    C_bar = tanh(np.add(np.dot(p.W_C.v, z), p.b_C.v))# write your code here\n",
        "    C = np.add(f*C_prev, i*C_bar)# write your code here\n",
        "    o = sigmoid(np.add(np.dot(p.W_o.v, z), p.b_o.v))# write your code here\n",
        "    h = o*tanh(C)# write your code here\n",
        "    v = np.add(np.dot(p.W_v.v, h), p.b_v.v) # write your code here\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK55433S3ipz",
        "colab_type": "code",
        "outputId": "0934d4c7-811b-4029-8156-bb744a386ba6",
        "colab": {}
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1GvKVWmTDt3H",
        "colab": {}
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcTqEGsG3ip5",
        "colab_type": "code",
        "outputId": "c017ba7b-bbc5-42e8-b71a-e6d1846fe436",
        "colab": {}
      },
      "source": [
        "print(z.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(195, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGVR0xi_3ip7",
        "colab_type": "code",
        "outputId": "38f47ea3-a57f-4856-bd20-6f0eacbaed7f",
        "colab": {}
      },
      "source": [
        " print(np.sum(z))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuHFnyMF3ip9",
        "colab_type": "code",
        "outputId": "3f900a05-2d57-49eb-a388-c26f63429e5b",
        "colab": {}
      },
      "source": [
        " print(np.sum(f))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zIa1jUZiGPmF",
        "colab": {}
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OJWoC3U1ITf8",
        "colab": {}
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0LTsublxIfFl",
        "colab": {}
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CQNxjTuZIia_",
        "colab": {}
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p8SrtJiwIsSm",
        "colab": {}
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ENQYU-7AIw0t",
        "colab": {}
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bR08TvcjI4Pf",
        "colab": {}
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZVDHbMb7JNGT",
        "colab": {}
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OQyNSL0iJOxH",
        "outputId": "88b9e891-8b0a-4274-ef2a-6e913a7e3766",
        "colab": {}
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "    if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "        g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "        g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "        pointer = 0\n",
        "\n",
        "\n",
        "    inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "    targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "    loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "    # Print every hundred steps\n",
        "    if iteration % 100 == 0:\n",
        "        update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "    update_paramters()\n",
        "\n",
        "    plot_iter = np.append(plot_iter, [iteration])\n",
        "    plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "    pointer += Time_steps\n",
        "    iteration += 1\n",
        "    iter = iter -1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " adiv>#b14,588;paKity:none}sereindex;tox:hildlactive}.gb_vd{margin-left:coloty-spamic;lort:100;w:ine-backgrours{dive_iampanst;cursor:{ppspacel}.gb_pd sgrnshatiomextEne;border-raft_ptay:0.1p;wightistuxt \n",
            "----\n",
            "iter 99900, loss 44.401556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmY4stj03iqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iter = 1000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "    if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "        g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "        g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "        pointer = 0\n",
        "\n",
        "\n",
        "    inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "    targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "    loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "    # Print every hundred steps\n",
        "    if iteration % 100 == 0:\n",
        "        update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "    update_paramters()\n",
        "\n",
        "    plot_iter = np.append(plot_iter, [iteration])\n",
        "    plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "    pointer += Time_steps\n",
        "    iteration += 1\n",
        "    iter = iter -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    }
  ]
}